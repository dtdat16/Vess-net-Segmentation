{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VessNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOKEbIr2lXJuxXHzM0s6Ftm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtdat16/Vess-net-Segmentation/blob/main/VessNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h3IFChZsUll",
        "outputId": "290779c1-7220-48d1-f41b-2df564deb349"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNKSpl2XsbtD"
      },
      "source": [
        "import os\n",
        "\n",
        "from torch.utils import data\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ImageFolder(data.Dataset):\n",
        "    def __init__(self, root, mode='train'):\n",
        "        \"\"\"Initializes image paths and preprocessing module.\"\"\"\n",
        "        self.root = root\n",
        "        self.image_dir = root + '/image'\n",
        "        # GT : Ground Truth\n",
        "        self.GT_dir = root + '/GT'\n",
        "\n",
        "        self.image_idx = list(map(lambda x:  x, os.listdir(self.image_dir)))\n",
        "\n",
        "        self.mode = mode\n",
        "        \n",
        "        print(\"image count in {} path :{}\".format(\n",
        "            self.mode, len(self.image_idx)))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Reads an image from a file and preprocesses it and returns.\"\"\"\n",
        "        image_path = self.image_dir + '/' + self.image_idx[index] \n",
        "\n",
        "\n",
        "        GT_path = self.GT_dir + '/' + self.image_idx[index]\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        GT = self.get_gt(GT_path)\n",
        "        Transform = []\n",
        "        Transform.append(T.ToTensor())\n",
        "        Transform = T.Compose(Transform)\n",
        "\n",
        "        image = Transform(image)\n",
        "        GT = Transform(GT) \n",
        "        GT = torch.squeeze(GT)\n",
        "        GT = GT.type(torch.LongTensor)\n",
        "        \n",
        "        return image, GT\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the total number of font files.\"\"\"\n",
        "        return len(self.image_idx)\n",
        "\n",
        "    def get_gt(self, gt_path):\n",
        "        img = Image.open(gt_path)\n",
        "        img_array = np.array(img)\n",
        "        h,w = img_array.shape\n",
        "        result = np.zeros(img_array.shape, dtype= int)\n",
        "        for i in range(0, h):\n",
        "            for j in range(0, w):\n",
        "                value = img_array[i][j]\n",
        "                if value > 50:\n",
        "                    result[i][j] = 1\n",
        "                else:\n",
        "                    result[i][j] = 0\n",
        "      \n",
        "        return result\n",
        "\n",
        "\n",
        "def get_loader(image_path, batch_size, num_workers=1, mode='train'):\n",
        "    \"\"\"Builds and returns Dataloader.\"\"\"\n",
        "\n",
        "    dataset = ImageFolder(root=image_path, mode=mode)\n",
        "    data_loader = data.DataLoader(\n",
        "        dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    return data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKdIxX9TstWt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class conv_block(nn.Module):\n",
        "    def __init__(self,ch_in,ch_out):\n",
        "        super(conv_block,self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class IRSP(nn.Module):\n",
        "    def __init__(self,ch_in,ch_out):\n",
        "        super(IRSP,self).__init__()\n",
        "        self.irsp = nn.Sequential(\n",
        "            nn.Conv2d(ch_in,ch_out, kernel_size=1,stride=1,padding=0,bias=True),\n",
        "            nn.BatchNorm2d(ch_out)\n",
        "        )\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.irsp(x)\n",
        "        return x\n",
        "\n",
        "class Vess_Net(nn.Module):\n",
        "    def __init__(self,input_ch= 3, output_ch= 2):\n",
        "        super(Vess_Net,self).__init__()\n",
        "        self.pool = nn.MaxPool2d(kernel_size= 2, stride=2, return_indices=True)\n",
        "        self.unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        #encoder block\n",
        "        self.econv_1_1 = conv_block(input_ch,64)\n",
        "        self.econv_1_2 = conv_block(64,64)\n",
        "        \n",
        "        self.econv_2_1 = conv_block(64,128)\n",
        "        self.irps_1 = IRSP(64,128)\n",
        "        self.econv_2_2 = conv_block(128,128)\n",
        "\n",
        "        self.econv_3_1 = conv_block(128,256)\n",
        "        self.irps_2 = IRSP(128,256)\n",
        "        self.econv_3_2 = conv_block(256,256)\n",
        "\n",
        "        self.econv_4_1 = conv_block(256,512)\n",
        "        self.irps_3 = IRSP(256,512)\n",
        "        self.econv_4_2 = conv_block(512,512)\n",
        "\n",
        "        #decoder block\n",
        "        self.dconv_4_2 = conv_block(512,512)\n",
        "        self.irps_4 = IRSP(512,256)\n",
        "        self.dconv_4_1 = conv_block(512,256)\n",
        "\n",
        "        self.dconv_3_2 = conv_block(256,256)\n",
        "        self.irps_5 = IRSP(256,128)\n",
        "        self.dconv_3_1 = conv_block(256,128)\n",
        "\n",
        "        self.dconv_2_2 = conv_block(128,128)\n",
        "        self.irps_6 = IRSP(128,64)\n",
        "        self.dconv_2_1 = conv_block(128,64)\n",
        "\n",
        "        self.dconv_1_2 = conv_block(64,64)\n",
        "        self.dconv_1_1 = conv_block(64,output_ch)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        #Encoder block 1\n",
        "        x_e_1_1 = self.econv_1_1(x)\n",
        "        x_e_1_1 = self.relu(x_e_1_1)\n",
        "        x_e_1_2 = self.econv_1_2(x_e_1_1)\n",
        "        x_e_1_2 = self.relu(x_e_1_2)\n",
        "        pool_1_size = x_e_1_2.size()\n",
        "        x_pool_1, indices_1 = self.pool(x_e_1_2)\n",
        "\n",
        "        #Encoder block 2\n",
        "        irsp1 = self.irps_1(x_pool_1)\n",
        "        x_e_2_1 = self.econv_2_1(x_pool_1)\n",
        "        x_e_2_1 = self.relu(x_e_2_1)\n",
        "        x_e_2_2 = self.econv_2_2(x_e_2_1)\n",
        "        x_e_2_2 = x_e_2_2 + irsp1\n",
        "        x_e_2_2 = self.relu(x_e_2_2)\n",
        "        pool_2_size = x_e_2_2.size()\n",
        "        x_pool_2, indices_2 = self.pool(x_e_2_2)\n",
        "\n",
        "        #Encoder block 3\n",
        "        irsp2 = self.irps_2(x_pool_2)\n",
        "        x_e_3_1 = self.econv_3_1(x_pool_2)\n",
        "        x_e_3_1 = self.relu(x_e_3_1)\n",
        "        x_e_3_2 = self.econv_3_2(x_e_3_1)\n",
        "        x_e_3_2 = x_e_3_2 + irsp2\n",
        "        x_e_3_2 = self.relu(x_e_3_2)\n",
        "        pool_3_size = x_e_3_2.size()\n",
        "        x_pool_3, indices_3 = self.pool(x_e_3_2)\n",
        "\n",
        "        #Encoder block 4\n",
        "        irsp3 = self.irps_3(x_pool_3)\n",
        "        x_e_4_1 = self.econv_4_1(x_pool_3)\n",
        "        x_e_4_1 = self.relu(x_e_4_1)\n",
        "        x_e_4_2 = self.econv_4_2(x_e_4_1)\n",
        "        x_e_4_2 = x_e_4_2 + irsp3\n",
        "        x_e_4_2 = self.relu(x_e_4_2)\n",
        "        pool_4_size = x_e_4_2.size()\n",
        "        x_pool_4, indices_4 = self.pool(x_e_4_2)\n",
        "\n",
        "        #Decoder block 4\n",
        "        x_unpool_4 = self.unpool(x_pool_4, indices_4,output_size= pool_4_size)\n",
        "        irsp4 = self.irps_4(x_unpool_4)\n",
        "        x_d_4_2 = self.dconv_4_2(x_unpool_4)\n",
        "        x_d_4_2 = self.relu(x_d_4_2)\n",
        "        x_d_4_2 = x_d_4_2 + x_e_4_1\n",
        "        x_d_4_1 = self.dconv_4_1(x_d_4_2)\n",
        "        x_d_4_1 = x_d_4_1 + irsp4\n",
        "        x_d_4_1 = self.relu(x_d_4_1)\n",
        "\n",
        "        #Decoder block 3\n",
        "        x_unpool_3 = self.unpool(x_d_4_1, indices_3, output_size= pool_3_size)\n",
        "        irsp5 = self.irps_5(x_unpool_3)\n",
        "        x_d_3_2 = self.dconv_3_2(x_unpool_3)\n",
        "        x_d_3_2 = self.relu(x_d_3_2)\n",
        "        x_d_3_2 = x_d_3_2 + x_e_3_1\n",
        "        x_d_3_1 = self.dconv_3_1(x_d_3_2)\n",
        "        x_d_3_1 = x_d_3_1 + irsp5\n",
        "        x_d_3_1 = self.relu(x_d_3_1)\n",
        "\n",
        "        #Decoder block 2 \n",
        "        x_unpool_2 = self.unpool(x_d_3_1, indices_2, output_size= pool_2_size)\n",
        "        irsp6 = self.irps_6(x_unpool_2)\n",
        "        x_d_2_2 = self.dconv_2_2(x_unpool_2)\n",
        "        x_d_2_2 = self.relu(x_d_2_2)\n",
        "        x_d_2_2 = x_d_2_2 + x_e_2_1\n",
        "        x_d_2_1 = self.dconv_2_1(x_d_2_2)\n",
        "        x_d_2_1 = x_d_2_1 + irsp6\n",
        "        x_d_2_1 = self.relu(x_d_2_1)\n",
        "\n",
        "        #Decoder block 1\n",
        "        x_unpool_1 = self.unpool(x_d_2_1, indices_1, output_size= pool_1_size)\n",
        "        x_d_1_2 = self.dconv_1_2(x_unpool_1)\n",
        "        x_d_1_2 = self.relu(x_d_1_2)\n",
        "        x_d_1_2 = x_d_1_2 + x_e_1_1\n",
        "        x_d_1_1 = self.dconv_1_1(x_d_1_2)\n",
        "        x_d_1_1 = self.relu(x_d_1_1)\n",
        "\n",
        "        return x_d_1_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqtwM8EIs6bL"
      },
      "source": [
        "import torch\n",
        "\n",
        "# SR : Segmentation Result\n",
        "# GT : Ground Truth\n",
        "\n",
        "def get_accuracy(SR,GT):\n",
        "\n",
        "    corr = torch.sum(SR == GT)\n",
        "    SR_dim = SR.dim()\n",
        "    tensor_size = SR.size(0)\n",
        "    for i in range(1, SR_dim):\n",
        "      tensor_size = tensor_size*SR.size(i)\n",
        "      \n",
        "    acc = float(corr)/float(tensor_size)\n",
        "\n",
        "    return acc\n",
        "\n",
        "def get_sensitivity(SR,GT,threshold=0.5):\n",
        "    # Sensitivity == Recall\n",
        "    # SR = SR > threshold\n",
        "    # GT = GT == torch.max(GT)\n",
        "\n",
        "    # TP : True Positive\n",
        "    # FN : False Negative\n",
        "    TP = (SR==1)&(GT==1)\n",
        "    FN = (SR==0)&(GT==1)\n",
        "\n",
        "    SE = float(torch.sum(TP))/(float(torch.sum(TP+FN)))     \n",
        "    \n",
        "    return SE\n",
        "\n",
        "def get_specificity(SR,GT,threshold=0.5):\n",
        "    # SR = SR > threshold\n",
        "    # GT = GT == torch.max(GT)\n",
        "\n",
        "    # TN : True Negative\n",
        "    # FP : False Positive\n",
        "    TN = (SR==0)&(GT==0)\n",
        "    FP = (SR==1)&(GT==0)\n",
        "\n",
        "    SP = float(torch.sum(TN))/(float(torch.sum(TN+FP)))\n",
        "    \n",
        "    return SP\n",
        "\n",
        "def get_JS(SR,GT,threshold=0.5):\n",
        "    # JS : Jaccard similarity\n",
        "    # SR = SR > threshold\n",
        "    # GT = GT == torch.max(GT)\n",
        "    \n",
        "    Inter = torch.sum(SR&GT)\n",
        "    Union = torch.sum(SR|GT)\n",
        "    \n",
        "    JS = float(Inter)/(float(Union))\n",
        "    \n",
        "    return JS\n",
        "\n",
        "def get_DC(SR,GT,threshold=0.5):\n",
        "    # DC : Dice Coefficient\n",
        "    # SR = SR > threshold\n",
        "    # GT = GT == torch.max(GT)\n",
        "\n",
        "    Inter = torch.sum(SR&GT)\n",
        "    DC = float(2*Inter)/(float(torch.sum(SR)+torch.sum(GT)))\n",
        "\n",
        "    return DC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o79oQVPetB82"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import optim\n",
        "import csv\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "import numpy as np\n",
        "\n",
        "def save_model(model, epoch, best_model_score,lr, optimizer, state_dict_dir, checkpoint_dir):\n",
        "        print(\"save model in the each epoch\")\n",
        "        checkpoint = {\n",
        "                'epoch': epoch, \n",
        "                'best_model_score': best_model_score,\n",
        "                'lr': lr,\n",
        "                'optimizer': optimizer.state_dict()\n",
        "                }\n",
        "        torch.save(model.state_dict(), f'{state_dict_dir}/state_dict_without_norm_50.pth')\n",
        "\n",
        "        file_name = checkpoint_dir + '/' + 'checkpoint_without_norm_50.pickle'\n",
        "\n",
        "        with open(file_name, 'wb+') as file:\n",
        "          pickle.dump(checkpoint, file)\n",
        "          \n",
        "def load_model_checkpoint(file_name, checkpoint_dir):\n",
        "    file_path = checkpoint_dir + '/' + file_name\n",
        "    print('loading model contained in the file', file_path)\n",
        "    if(Path(file_path).exists()):\n",
        "      checkpoint = {}\n",
        "      with open(file_path, 'rb') as file:\n",
        "        checkpoint = pickle.load(file)\n",
        "        return {\n",
        "            'epoch': checkpoint['epoch'], \n",
        "            'best_model_score': checkpoint['best_model_score'],\n",
        "            'lr': checkpoint['lr'],\n",
        "            'optimizer': checkpoint['optimizer']\n",
        "            }\n",
        "    else:\n",
        "        raise FileNotFoundError('Model file not found')\n",
        "        \n",
        "def optimizer_to(optim, device):\n",
        "    for param in optim.state.values():\n",
        "        # Not sure there are any global tensors in the state dict\n",
        "        if isinstance(param, torch.Tensor):\n",
        "            param.data = param.data.to(device)\n",
        "            if param._grad is not None:\n",
        "                param._grad.data = param._grad.data.to(device)\n",
        "        elif isinstance(param, dict):\n",
        "            for subparam in param.values():\n",
        "                if isinstance(subparam, torch.Tensor):\n",
        "                    subparam.data = subparam.data.to(device)\n",
        "                    if subparam._grad is not None:\n",
        "                        subparam._grad.data = subparam._grad.data.to(device)\n",
        "\n",
        "def save_img(img_array, save_path):\n",
        "    im = Image.fromarray(np.uint8(cm.gist_earth(img_array)*255))\n",
        "    im.save(save_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMiwh_-HUDxp"
      },
      "source": [
        "import torch\n",
        "\n",
        "def train(model, optimizer, train_loader,valid_loader, state_dict_dir,checkpoint_dir, lr, current_epoch, num_epochs, device, criterion, best_model_score, net_path, result_path):\n",
        "        \"\"\"Train encoder, generator and discriminator.\"\"\"\n",
        "\n",
        "        #====================================== Training ===========================================#\n",
        "        #===========================================================================================#\n",
        "\n",
        "        while current_epoch < num_epochs:\n",
        "            \n",
        "            epoch = current_epoch\n",
        "            model.train(True)\n",
        "            epoch_loss = 0\n",
        "            epoch_acc = 0\n",
        "            acc = 0.  # Accuracy\n",
        "            SE = 0.\t\t# Sensitivity (Recall)\n",
        "            SP = 0.\t\t# Specificity\n",
        "            JS = 0.\t\t# Jaccard Similarity\n",
        "            DC = 0.\t\t# Dice Coefficient\n",
        "            length = 0\n",
        "\n",
        "            for images, GT in train_loader:\n",
        "                # GT : Ground Truth\n",
        "\n",
        "                images = images.to(device)\n",
        "                \n",
        "                GT = GT.to(device)\n",
        "\n",
        "                # SR : Segmentation Result\n",
        "                SR = model(images)\n",
        "                SR_prob = torch.softmax(SR, dim= 1)\n",
        "                _,preds = torch.max(SR_prob, 1)\n",
        "                loss = criterion(SR_prob, GT)\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                # Backprop + optimize\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                preds = torch.squeeze(preds)\n",
        "                GT = torch.squeeze(GT)\n",
        "                acc += get_accuracy(preds, GT)\n",
        "                SE += get_sensitivity(preds, GT)\n",
        "                SP += get_specificity(preds, GT)\n",
        "                JS += get_JS(preds, GT)\n",
        "                DC += get_DC(preds, GT)\n",
        "                length += images.size(0)\n",
        "\n",
        "            acc = acc/length\n",
        "            SE = SE/length\n",
        "            SP = SP/length\n",
        "            JS = JS/length\n",
        "            DC = DC/length\n",
        "\n",
        "            # Print the log info\n",
        "            print('Epoch [%d/%d], Loss: %.4f, \\n[Training] Acc: %.4f, SE: %.4f, SP: %.4f, JS: %.4f, DC: %.4f' % (\n",
        "              epoch+1, num_epochs,\n",
        "              epoch_loss,\n",
        "              acc, SE, SP, JS, DC))\n",
        "\n",
        "            #===================================== Validation ====================================#\n",
        "            model.train(False)\n",
        "            model.eval()\n",
        "\n",
        "            acc = 0.  # Accuracy\n",
        "            SE = 0.\t\t# Sensitivity (Recall)\n",
        "            SP = 0.\t\t# Specificity\n",
        "            JS = 0.\t\t# Jaccard Similarity\n",
        "            DC = 0.\t\t# Dice Coefficient\n",
        "            length = 0\n",
        "            model_score = 0\n",
        "            \n",
        "            for i, (images, GT) in enumerate(valid_loader):\n",
        "\n",
        "                images = images.to(device)\n",
        "                GT = GT.to(device)\n",
        "                \n",
        "                SR = model(images)\n",
        "                SR_prob = torch.softmax(SR, dim= 1)\n",
        "                _,preds = torch.max(SR_prob, 1)\n",
        "\n",
        "                preds = torch.squeeze(preds)\n",
        "                GT = torch.squeeze(GT)\n",
        "                acc += get_accuracy(preds, GT)\n",
        "                SE += get_sensitivity(preds, GT)\n",
        "                SP += get_specificity(preds, GT)\n",
        "                JS += get_JS(preds, GT)\n",
        "                DC += get_DC(preds, GT)\n",
        "                length += images.size(0)\n",
        "\n",
        "            acc = acc/length\n",
        "            SE = SE/length\n",
        "            SP = SP/length\n",
        "            JS = JS/length\n",
        "            DC = DC/length\n",
        "            model_score = JS + DC\n",
        "\n",
        "            print('[Validation] Acc: %.4f, SE: %.4f, SP: %.4f, JS: %.4f, DC: %.4f' % (\n",
        "                    acc, SE, SP, JS, DC))\n",
        "\n",
        "            # Save Best U-Net model\n",
        "            if model_score > best_model_score:\n",
        "                best_model_score = model_score # float type\n",
        "                best_epoch = epoch\n",
        "                best_net = model.state_dict()\n",
        "                print('Best model score : %.4f' %\n",
        "                      (best_model_score))\n",
        "                torch.save(best_net, net_path)\n",
        "\n",
        "                f = open(os.path.join(\n",
        "                    result_path, 'result-validate.csv'), 'a', encoding='utf-8', newline='')\n",
        "                wr = csv.writer(f)\n",
        "                wr.writerow([best_epoch, num_epochs])\n",
        "                f.close()\n",
        "            \n",
        "            save_model(model,current_epoch,best_model_score,lr,optimizer,state_dict_dir,checkpoint_dir)\n",
        "            current_epoch += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgncgcQh_1Ta"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch\n",
        "model = Vess_Net(input_ch= 3, output_ch= 2)\n",
        "lr = 0.0005\n",
        "print('build_model')\n",
        "optimizer = optim.Adam(model.parameters(), lr= lr, eps= 0.000001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "state_dict_dir= '/content/gdrive/MyDrive/train_data_hrf_vess_net/state_dicts'\n",
        "result_path = '/content/gdrive/MyDrive/train_data_hrf_vess_net/result'\n",
        "net_path =  '/content/gdrive/MyDrive/train_data_hrf_vess_net/models/best_model_without_norm_50.pth'\n",
        "checkpoint_dir= '/content/gdrive/MyDrive/train_data_hrf_vess_net/checkpoints'\n",
        "\n",
        "current_epoch= 0\n",
        "num_epochs= 100\n",
        "best_model_score= 0\n",
        "\n",
        "train_path = '/content/gdrive/MyDrive/train_data_hrf_vess_net/training'\n",
        "train_loader = get_loader(train_path, 1, num_workers= 4)\n",
        "val_path = '/content/gdrive/MyDrive/train_data_hrf_vess_net/validate'\n",
        "valid_loader = get_loader(val_path, 1, num_workers= 4, mode='valid')\n",
        "\n",
        "try:\n",
        "    checkpoint = load_model_checkpoint('checkpoint_without_norm_50.pickle', checkpoint_dir)\n",
        "    print('checkpoint found. loading state...')\n",
        "    current_epoch = checkpoint['epoch'] + 1\n",
        "    best_model_score = checkpoint['best_model_score']\n",
        "    lr = checkpoint['lr']\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    optimizer_to(optimizer,device)\n",
        "    state_dict_path = f'{state_dict_dir}/state_dict_without_norm_50.pth'\n",
        "    model.load_state_dict(torch.load(state_dict_path))\n",
        "    print('checkpoint state loaded successfully')\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print('the first training')\n",
        "print(f'current_epoch: {current_epoch}, best_unet_score: {best_model_score}, lr: {lr}')\n",
        "\n",
        "model.to(device)\n",
        "train(model, optimizer, train_loader,valid_loader, state_dict_dir,checkpoint_dir, lr, current_epoch, num_epochs, device, criterion, best_model_score, net_path, result_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFLJoPFRUuWK"
      },
      "source": [
        "def test(model, test_loader,result_path,device):\n",
        "        \n",
        "        model.train(False)\n",
        "        model.eval()\n",
        "\n",
        "        acc = 0.  # Accuracy\n",
        "        SE = 0.\t\t# Sensitivity (Recall)\n",
        "        SP = 0.\t\t# Specificity\n",
        "        PC = 0. \t# Precision\n",
        "        F1 = 0.\t\t# F1 Score\n",
        "        JS = 0.\t\t# Jaccard Similarity\n",
        "        DC = 0.\t\t# Dice Coefficient\n",
        "        length = 0\n",
        "        for i, (images, GT) in enumerate(test_loader):\n",
        "\n",
        "            images = images.to(device)\n",
        "            GT = GT.to(device)\n",
        "            SR = model(images)\n",
        "            SR_prob = torch.softmax(SR, dim= 1)\n",
        "            _,preds = torch.max(SR_prob, 1)\n",
        "            preds = torch.squeeze(preds)\n",
        "            GT = torch.squeeze(GT)\n",
        "            acc += get_accuracy(preds, GT)\n",
        "            SE += get_sensitivity(preds, GT)\n",
        "            SP += get_specificity(preds, GT)\n",
        "            PC += get_precision(preds, GT)\n",
        "            F1 += get_F1(preds, GT)\n",
        "            JS += get_JS(preds, GT)\n",
        "            DC += get_DC(preds, GT)\n",
        "\n",
        "            length += images.size(0)\n",
        "            \n",
        "            preds = preds.type(torch.FloatTensor)\n",
        "            \n",
        "            GT = GT.type(torch.FloatTensor)\n",
        "            torchvision.utils.save_image(images.data.cpu(),os.path.join(result_path + f'/{i}',f'test_image_{i}_50.png'))\n",
        "            save_img(preds.numpy(),os.path.join(result_path + f'/{i}',f'test_SR_{i}_50.png'))\n",
        "            save_img(GT.numpy(),os.path.join(result_path + f'/{i}',f'test_GT_{i}_50.png'))\n",
        "\n",
        "        acc = acc/length\n",
        "        SE = SE/length\n",
        "        SP = SP/length\n",
        "        PC = PC/length\n",
        "        F1 = F1/length\n",
        "        JS = JS/length\n",
        "        DC = DC/length\n",
        "        print('[TEST] Acc: %.4f, SE: %.4f, SP: %.4f, PC: %.4f, F1: %.4f, JS: %.4f, DC: %.4f' % (\n",
        "                    acc, SE, SP, PC, F1, JS, DC))\n",
        "        \n",
        "\n",
        "        f = open(os.path.join(result_path, 'result.csv'),\n",
        "                 'a', encoding='utf-8', newline='')\n",
        "        wr = csv.writer(f)\n",
        "        wr.writerow([acc, SE, SP, PC, F1, JS, DC])\n",
        "        f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5zFEV1Arr7C",
        "outputId": "55265e09-ff61-4f27-9eec-082639a8a06b"
      },
      "source": [
        "test_loader = get_loader(image_path='/content/gdrive/MyDrive/STARE/test',\n",
        "                        batch_size=1,\n",
        "                        num_workers=0,\n",
        "                        )\n",
        "model = Vess_Net(input_ch= 3, output_ch= 2)\n",
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/STARE/state_dicts/state_dict_without_norm_50.pth', map_location=torch.device('cpu')))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "result_path = '/content/gdrive/MyDrive/STARE/result'\n",
        "model.to(device)\n",
        "\n",
        "test(model, test_loader, result_path,device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image count in train path :20\n",
            "[TEST] Acc: 0.9698, SE: 0.7632, SP: 0.9883, PC: 0.8843, F1: 0.8004, JS: 0.6803, DC: 0.8004\n"
          ]
        }
      ]
    }
  ]
}